# -*- coding: utf-8 -*-
"""webscrapersummarizer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cglsu5HA3KsYG_NIGyRiilCeNZPloZM3
"""

import requests
from bs4 import BeautifulSoup
from IPython.display import Markdown ,display

!pip install transformers torch

from transformers import T5Tokenizer,T5ForConditionalGeneration

model_name ="t5-small"
tokenizer = T5Tokenizer.from_pretrained(model_name)
model = T5ForConditionalGeneration.from_pretrained(model_name)

headers = {
 "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36"
}

class Website:
  def __init__(self,url):
    self.url = url
    response = requests.get(url,headers=headers)
    self.soup = BeautifulSoup(response.text,'html.parser')
    self.title = self.soup.title.string if self.soup.title else "No title found"
    for irrelevant in self.soup.body(["script","style","img","input"]):
      irrelevant.decompose()
    self.text = self.soup.get_text(separator="\n",strip = True)

!pip install -U langchain-community

from langchain.document_loaders import WebBaseLoader
from langchain.schema import Document
kb = WebBaseLoader("https://www.nationalgeographic.com/")
data = kb.load()
print(data[0].metadata['title'])
print(data[0].page_content)

system_prompt = "You are a very casual assistant that analyzes the contents of a website \
and provides a short summary, ignoring text that might be navigation related. \
Respond in markdown."

def user_prompt_for(website: Document):
  # the website variable, which is data[0], has the metadata, which contains the title.
  user_prompt = f"You are looking at a website titled{website.metadata['title']}"
  user_prompt += "\nThe contents of this website is as follows; \
please provide a short summary of this website in markdown. \
If it includes news or announcements, then summarize these too.\n\n"
  user_prompt += website.page_content # we also need to use website.page_content rather than website.text
  return user_prompt

print(user_prompt_for(website=data[0]))

def messages_for(website: Document):
  return[{
      "role":"system","content":system_prompt
  },{
      "role":"user","content":user_prompt_for(website)
  }]

messages_for(website=data[0])

def summarize(url):
  kb = WebBaseLoader(url)
  data = kb.load()
  # the messages_for function returns a list of dictionaries,
  # where each dictionary represents a role (system or user) and the content.
  messages = messages_for(data[0])
  # extract the user prompt from the messages which is in the second dictionary in the list.
  user_prompt = messages[1]['content']

  # Tokenize the user prompt with the T5 tokenizer
  inputs = tokenizer(user_prompt, return_tensors="pt", max_length=1024, truncation=True)

  summary_ids = model.generate(inputs["input_ids"],
                              attention_mask=inputs["attention_mask"],
                              max_length=150,
                              min_length=50,
                              length_penalty=2.0,
                              num_beams=4,
                              early_stopping=True)

  # Decode the generated summary tokens
  summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
  return summary

summarize("https://www.nationalgeographic.com/")